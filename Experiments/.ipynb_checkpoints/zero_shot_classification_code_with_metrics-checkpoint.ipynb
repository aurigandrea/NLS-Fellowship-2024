{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "151f01c6",
   "metadata": {},
   "source": [
    "\n",
    "#  Zero-Shot Text Classification with Evaluation Metrics\n",
    "\n",
    "This notebook uses a transformer-based **zero-shot classification** model (`facebook/bart-large-mnli`) to assign health-related categories to text content. It evaluates model performance using a manually labeled column and visualises results with a confusion matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744f556f",
   "metadata": {},
   "source": [
    "\n",
    "## üì¶ Import Libraries\n",
    "\n",
    "We use:\n",
    "- `pandas` for data handling\n",
    "- `transformers` for zero-shot classification\n",
    "- `sklearn.metrics` for evaluation\n",
    "- `seaborn` and `matplotlib` for visualizations\n",
    "- `ctypes` to prevent the system from sleeping during long runs (Windows-only)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208eda91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import ctypes\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7858343",
   "metadata": {},
   "source": [
    "\n",
    "## üí§ Prevent System from Sleeping (Optional)\n",
    "\n",
    "These functions are for Windows systems and prevent sleep while processing large batches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d999db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prevent_sleep():\n",
    "    try:\n",
    "        ctypes.windll.kernel32.SetThreadExecutionState(0x80000002)  # ES_CONTINUOUS | ES_SYSTEM_REQUIRED\n",
    "        print(\"Sleep prevention activated.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to activate sleep prevention: {e}\")\n",
    "\n",
    "def restore_sleep():\n",
    "    try:\n",
    "        ctypes.windll.kernel32.SetThreadExecutionState(0x80000000)  # ES_CONTINUOUS\n",
    "        print(\"Sleep prevention deactivated.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to deactivate sleep prevention: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dac2d1e",
   "metadata": {},
   "source": [
    "\n",
    "## üìÑ Load and Prepare Data\n",
    "\n",
    "We load the dataset and fill in any missing values in the text columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d787813d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('NLS_classification_new manual.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(df.shape)\n",
    "\n",
    "text_columns = ['description', 'title', 'keywords', 'summary', 'full_text']\n",
    "for col in text_columns:\n",
    "    df[col] = df[col].fillna('').astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac1a7d5",
   "metadata": {},
   "source": [
    "\n",
    "## üè∑Ô∏è Define Candidate Labels\n",
    "\n",
    "These are the category labels the model will try to classify into.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8075d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "candidate_labels = [\n",
    "    'Medicine not part of mainstream medicine, fringe debates, and treatments aimed at aesthetics', \n",
    "    'Includes issues connected to pregnancy, childbirth, and abortion', \n",
    "    'All topics related to cancer', \n",
    "    'Cardiovascular health issues',\n",
    "    'Health issues related to children, parenting, and teens',\n",
    "    'Includes COVID-19 and related vaccination debates',\n",
    "    'Topics related to dementia',\n",
    "    'Dental health issues',\n",
    "    'All topics related to diabetes',\n",
    "    'Includes chronic diseases, specific acute conditions, and disabilities',\n",
    "    'Health issues related to the LGBTQ+ community, including transgender issues',\n",
    "    'All topics related to mental health',\n",
    "    'Includes neurodivergent conditions such as autism, ADHD, Down syndrome, learning difficulties, etc.',\n",
    "    'Topics on nutrition and physical fitness',\n",
    "    'Research and general health information resources not fitting into other categories',\n",
    "    'Health services provided for profit, not fitting into other categories',\n",
    "    'Includes sexual health and sexually transmitted infections',\n",
    "    'Social activism and charity work related to health not fitting into other categories',\n",
    "    'Includes topics on substance use and addiction',\n",
    "    'All topics related to surgical procedures',\n",
    "    'Health issues related to women, including menstruation, menopause, PCOS, and endometriosis'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f6d0bf",
   "metadata": {},
   "source": [
    "\n",
    "## ü§ñ Load Zero-Shot Classification Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8613fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier = pipeline('zero-shot-classification', model='facebook/bart-large-mnli')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cf4673",
   "metadata": {},
   "source": [
    "\n",
    "## üß† Classify Text in Batches\n",
    "\n",
    "We create helper functions to classify the text and write results in chunks, which is useful for large datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48a7f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def classify_batch(texts, labels):\n",
    "    if not texts or not labels:\n",
    "        raise ValueError(\"Empty batch or labels\")\n",
    "    results = classifier(texts, labels)\n",
    "    return [(result['labels'][0], result['scores'][0]) for result in results]\n",
    "\n",
    "def process_and_save_chunk(chunk, chunk_index, batch_size=16):\n",
    "    predicted_categories = []\n",
    "    confidence_scores = []\n",
    "    num_batches = (len(chunk) + batch_size - 1) // batch_size\n",
    "\n",
    "    for i in range(0, len(chunk), batch_size):\n",
    "        batch_texts = chunk[text_columns].iloc[i:i+batch_size].apply(lambda row: ' '.join(row.values.astype(str)), axis=1).tolist()\n",
    "        \n",
    "        if not batch_texts:\n",
    "            predicted_categories.extend([None] * batch_size)\n",
    "            confidence_scores.extend([None] * batch_size)\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            batch_results = classify_batch(batch_texts, candidate_labels)\n",
    "            categories, scores = zip(*batch_results)\n",
    "            predicted_categories.extend(categories)\n",
    "            confidence_scores.extend(scores)\n",
    "        except:\n",
    "            predicted_categories.extend([None] * batch_size)\n",
    "            confidence_scores.extend([None] * batch_size)\n",
    "\n",
    "    if len(predicted_categories) < len(chunk):\n",
    "        predicted_categories.extend([None] * (len(chunk) - len(predicted_categories)))\n",
    "        confidence_scores.extend([0.0] * (len(chunk) - len(confidence_scores)))\n",
    "\n",
    "    chunk['predicted_category'] = predicted_categories[:len(chunk)]\n",
    "    chunk['confidence_score'] = confidence_scores[:len(chunk)]\n",
    "    chunk.to_csv(f'chunk_{chunk_index}_classified.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea66c0b8",
   "metadata": {},
   "source": [
    "\n",
    "## üîÑ Process Data in Chunks\n",
    "\n",
    "This avoids memory issues and simulates real-world batch classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e01ec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prevent_sleep()\n",
    "\n",
    "chunk_size = 200\n",
    "chunks = [df[i:i+chunk_size] for i in range(0, len(df), chunk_size)]\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    process_and_save_chunk(chunk, idx)\n",
    "\n",
    "restore_sleep()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6d3559",
   "metadata": {},
   "source": [
    "\n",
    "## üß© Merge and Save Final Results\n",
    "\n",
    "We recombine all the classified chunks and save a final CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0d7e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classified_dfs = [pd.read_csv(f'chunk_{i}_classified.csv') for i in range(len(chunks))]\n",
    "final_df = pd.concat(classified_dfs, ignore_index=True)\n",
    "final_df.to_csv('NLS_classified_new.csv', index=False)\n",
    "print(\"Final DataFrame with classifications saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a808af0",
   "metadata": {},
   "source": [
    "\n",
    "## üìè Evaluate Classifier Performance\n",
    "\n",
    "We compare model predictions to manually labeled categories using accuracy, precision, recall, F1 score, and a confusion matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6a3f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_df['manual_label'] = final_df['manual_label'].fillna('unknown')\n",
    "final_df['predicted_category'] = final_df['predicted_category'].fillna('unknown')\n",
    "\n",
    "accuracy = accuracy_score(final_df['manual_label'], final_df['predicted_category'])\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "    final_df['manual_label'], final_df['predicted_category'], average='weighted', zero_division=0\n",
    ")\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03876593",
   "metadata": {},
   "source": [
    "\n",
    "## üìã Classification Report and Confusion Matrix\n",
    "\n",
    "We show a detailed report of performance per label and a heatmap for the confusion matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8f6b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(final_df['manual_label'], final_df['predicted_category']))\n",
    "\n",
    "conf_matrix = confusion_matrix(final_df['manual_label'], final_df['predicted_category'])\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(conf_matrix, annot=False, cmap='Blues', xticklabels=candidate_labels, yticklabels=candidate_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
