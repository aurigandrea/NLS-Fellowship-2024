{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4111cdfc",
   "metadata": {},
   "source": [
    "\n",
    "# Summarizing articles using T5\n",
    "\n",
    "In this notebook, we use a pre-trained [T5 model](https://huggingface.co/t5-small) from Hugging Face to generate summaries of long-form text data (like newspaper articles). We apply it to a DataFrame containing enhanced metadata with the scraped content and export the resulting summaries. You can chose this summary over the NLP-based one for future analysis or categorisation of the collection content. \n",
    "\n",
    "Running this notebook takes time, please make sure your computer is charging, your internet connection is stable, and sleep mode is disabled.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af54bef",
   "metadata": {},
   "source": [
    "\n",
    "##  Import required libraries\n",
    "\n",
    "We begin by importing the libraries we need:\n",
    "- `pandas` for handling tabular data\n",
    "- `transformers` from Hugging Face to load and use the T5 model\n",
    "- `tqdm` for progress bars during processing\n",
    "- `torch` as the backend framework for the T5 model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be177022",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2d9ddd",
   "metadata": {},
   "source": [
    "\n",
    "## Load the T5 Model and Tokenizer\n",
    "\n",
    "We initialise the T5 model and tokenizer. \n",
    "We use the `\"t5-small\"` version for speed and simplicity, though larger versions (like `\"t5-base\"` or `\"t5-large\"`) could give better results at the cost of more memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c4daff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialise T5 model and tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9484b3e",
   "metadata": {},
   "source": [
    "\n",
    "##  Load the Dataset\n",
    "\n",
    "We load the DataFrame from a CSV file named `AoT_enhanced.csv`, \n",
    "which is expected to contain a column named `full_text` with the raw article text,\n",
    "and a `url` column for reference. This dataset contains the columns with the parsed title, keywords, and summaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27edee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the DataFrame with pre-parsed full text\n",
    "df = pd.read_csv('data/AoT5_enhanced.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f78971d",
   "metadata": {},
   "source": [
    "\n",
    "## Ensure text column is string type\n",
    "\n",
    "Before processing, we make sure that the `full_text` column is properly cast to string type,\n",
    "since the T5 model expects a text input.\n",
    "Missing or NaN values will be converted to the string `\"nan\"` at this stage,\n",
    "so we handle that later in our loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5ddc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Ensure 'full_text' column is of string type and handle NaNs\n",
    "df['full_text'] = df['full_text'].astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bccf66",
   "metadata": {},
   "source": [
    "\n",
    "##  Define function to process text with T5\n",
    "\n",
    "We define a function `process_with_t5()` that:\n",
    "1. Adds the \"summarize:\" prefix expected by T5.\n",
    "2. Tokenizes the input and truncates to 1024 tokens.\n",
    "3. Generates a summary with beam search decoding.\n",
    "4. Returns the summary.\n",
    "\n",
    "Note: Although the function returns a placeholder for keywords,\n",
    "T5 is not designed for keyword extraction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763714d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to generate summary and keywords using T5\n",
    "def process_with_t5(text):\n",
    "    try:\n",
    "        # Summarization\n",
    "        input_text = \"summarize: \" + text\n",
    "        inputs = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "        outputs = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "        summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "        # Keyword Extraction\n",
    "        keywords = \"Keywords extraction not implemented for T5\"\n",
    "\n",
    "        return summary, keywords\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text with T5: {e}\")\n",
    "        return \"Error in T5 processing\", \"Error in T5 processing\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c893ae5c",
   "metadata": {},
   "source": [
    "\n",
    "##  Loop through the dataset and generate summaries\n",
    "\n",
    "We loop through each row of the DataFrame and:\n",
    "- Skip empty or invalid text values\n",
    "- Use the `process_with_t5()` function to generate a summary\n",
    "- Append the results (summary and placeholder keywords) to new lists\n",
    "\n",
    "We track progress with `tqdm` for a visual progress bar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cdde4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply T5 on the pre-parsed full text\n",
    "summaries = []\n",
    "keywords = []\n",
    "urls = []\n",
    "\n",
    "with tqdm(total=len(df), desc=\"Processing with T5\", unit=\"text\") as pbar:\n",
    "    for index, row in df.iterrows():\n",
    "        full_text = row['full_text']\n",
    "        \n",
    "        if pd.isna(full_text) or not isinstance(full_text, str) or full_text.strip() == \"\":\n",
    "            summary = \"No text available\"\n",
    "            keyword = \"No keywords available\"\n",
    "        else:\n",
    "            summary, keyword = process_with_t5(full_text)\n",
    "        \n",
    "        summaries.append(summary)\n",
    "        keywords.append(keyword)\n",
    "        urls.append(row['url'])\n",
    "        pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9424add3",
   "metadata": {},
   "source": [
    "\n",
    "##  Add generated summaries to the DataFrame\n",
    "\n",
    "We add two new columns to the original DataFrame:\n",
    "- `LLM summary`: the generated summary\n",
    "\n",
    "The 'LLM' prefix indicates the values were generated using a language model (T5).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9874b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['LLM summary'] = summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39ed798",
   "metadata": {},
   "source": [
    "\n",
    "##  Ensure title and keyword columns exist\n",
    "\n",
    "As a safety check, we ensure the original `title` and `keywords` columns still exist.\n",
    "If not, we add them back. \n",
    "(This block assumes they may already be missing or need to be restored.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449aeffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'title' not in df.columns:\n",
    "    df['title'] = df['title']\n",
    "if 'keywords' not in df.columns:\n",
    "    df['keywords'] = df['keywords']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5428b305",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸ“Š Preview and clean the DataFrame\n",
    "\n",
    "We print a few rows to inspect the result and display the full DataFrame with all columns and rows visible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c04f169",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(df.head())\n",
    "print(df.shape)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac088ef",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸ’¾ Export the final data\n",
    "\n",
    "Finally, we export the updated DataFrame to a CSV file, which now includes the generated summaries.\n",
    "Define your own destination folder and file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd1e213",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_csv('Aot_enhanced_with_LLM_summaries.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
